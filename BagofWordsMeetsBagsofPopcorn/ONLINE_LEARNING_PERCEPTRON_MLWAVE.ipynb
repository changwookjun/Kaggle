{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONLINE LEARNING PERCEPTRON (MLWAVE)\n",
    "=========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Let’s take a look at the perceptron : the simplest artificial neuron\n",
    "    \n",
    "This article goes from a concept devised in 1943 to a Kaggle competition in 2015. It shows that a single artificial neuron can get 0.95 AUC on an NLP sentiment analysis task (predicting if a movie review is positive or negative).</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "McCulloch-Pitts Neuron\n",
    "======================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./ONLINE_LEARNING/McCulloch-Pitts.jpg \"Neuron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경학자인 McCulloch와 논리학자인 Pitts라는 두 연구자가 1943년의 논문 “a Logical Calculus of the Ideas Immanent in Nervous Activity”(신경 행동에서 내재적 사고의 논리적 계산) 으로 시작되었다.\n",
    "논문 : https://link.springer.com/article/10.1007%2FBF02478259\n",
    "\n",
    "\n",
    "인공 신경망에 기인한 네트워크를 분석하고 그들이 어떻게 간단한 논리적 기능을 하는지 보여주었다. \n",
    "그들은 후에 신경 네트워크라 부르는 기술을 첫번째로 연구한 사람이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./ONLINE_LEARNING/Neuron.png \"Neuron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example\n",
    "==========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, 새가 씨앗과 같이 작은 물체를 먹으려고 한다. 이 행동을 표로 나타내면 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./ONLINE_LEARNING/1.png \"Neuron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AND 연산 McCulloch-Pitts Neuron으로 위 표를 모델링 할 수 있다. 활성화 임계 값을 1.5로 설정하면 \"BROWN\"및 \"ROUND\"속성이 모두 충족 될 때만 뉴런이 실행된다. 그러면 입력 합계는 2 (1 + 1)로 1.5의 활성화 임계 값보다 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./ONLINE_LEARNING/2.png \"Neuron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron\n",
    "=========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Perceptron wiki : https://ko.wikipedia.org/wiki/%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./ONLINE_LEARNING/3.png \"Neuron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론(perceptron)은 인공신경망의 한 종류로서, 1957년에 코넬 항공 연구소(Cornell Aeronautical Lab)의 프랑크 로젠블라트 (Frank Rosenblatt)에 의해 고안되었다. \n",
    "이것은 가장 간단한 형태의 피드포워드(Feedforward) 네트워크 - 선형분류기- 으로도 볼 수 있다. \n",
    "퍼셉트론 알고리즘은 하드웨어로 구현 된 최초의 인공 신경망이었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1960년 코넬 항공 연구소의 연구원은 미 해군 연구청의 자금으로 무작위로 400개의 광전지를 하나의 퍼셉트론에 연결하여 \"마크 1 퍼셉트론 (Mark 1 perceptron)\"이 탄생해 이것으로 기본 이미지 인식이 가능했다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론이 동작하는 방식은 각 노드의 가중치와 입력치를 곱한 것을 모두 합한 값이 활성함수에 의해 판단되는데, 그 값이 임계치(보통 0)보다 크면 뉴런이 활성화되고 결과값으로 1을 출력한다. 뉴런이 활성화되지 않으면 결과값으로 -1을 출력한다.\n",
    "\n",
    "마빈 민스키와 시모어 페퍼트는 저서 \"퍼셉트론\"에서 단층 퍼셉트론은 XOR 연산이 불가능하지만, 다층 퍼셉트론으로는 XOR 연산이 가능함을 보였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./ONLINE_LEARNING/4.png \"Neuron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론은 지도학습 분류기의 일종이다. 이전 값에 대한 학습으로 예측을 한다.\n",
    "\n",
    "퍼셉트론은 들어오는 연결에 가중치를 할당하여 작동한다. McCulloch-Pitts Neuron을 사용하여 들어오는 연결에서 값의 합계를 구하고 다음 특정 임계 값보다 높거나 낮은 지 확인했다. 내적을 구하는 대신 퍼셉트론을 사용했다. 여기에서는 들어오는 각 값에 가중치를 곱해서 합계를 구했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>sum: (value1 \\* weight1) + (value2 \\* weight2)\n",
    "\n",
    "weights[feature_index] += learning_rate \\* error \\* feature_value </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측이 올 바르면 오류는 \"0\"이고 가중치 만 남겨 둡니다. 예측이 틀린 경우 오류는 \"-1\"또는 \"1\"이고 퍼셉트론은 다음과 같이 가중치를 업데이트합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online Learning Perceptron in Python\n",
    "===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬으로 표준 라이브러리를 사용해서 위의 퍼셉트론 알고리즘을 구현했기 때문에 스크립트가 PyPy에서 실행되고 3-4배의 속도향상이 있다. 여기에 사용된 알고리즘은 Kaggle 포럼에서 처음 발견 된 tinrtgu의 온라인 로지스틱 회귀 스크립트에서 큰 영감을 얻었다고 한다.\n",
    "\n",
    "다음 경진대회에서 Vowpal Wabbit을 통한 해시트릭을 사용하였고 코드가 공개되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/criteo-display-ad-challenge/discussion/10322\n",
    "https://kaggle2.blob.core.windows.net/forum-message-attachments/53646/1539/fast_solution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Online Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>wiki : https://en.wikipedia.org/wiki/Online_machine_learning</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론은 온라인 학습이 가능하다(한 번에 하나씩 샘플을 통해 학습). 메모리에 전체 데이터 세트가 필요하지 않으므로(out-of-core) 더 큰 데이터 세트에 유용하다. 여기에서는 Vowpal Wabbit에서 온라인 학습 코드를 가져왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vowpal Wabbit : http://hunch.net/~vw/\n",
    "\n",
    "\n",
    "Hashing Representations : http://hunch.net/~jl/projects/hash_reps/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hashing trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터화 해싱 트릭은 Vowpal Wabbit (John Langford)에서 시작되었습니다. 이 트릭은 perceptron으로 들어오는 연결 수를 고정 된 크기로 설정합니다. 고정 된 크기보다 낮은 숫자로 모든 원시 피처를 해싱합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'movie', 'good']\n",
      "[(724, 1), (500, 1), (133, 1)]\n"
     ]
    }
   ],
   "source": [
    "sample = \"This movie good\"\n",
    "fixed_size = 1024\n",
    "\n",
    "print(sample.split())\n",
    "\n",
    "features = [(hash(f) % fixed_size, 1) for f in sample.split()]\n",
    "\n",
    "# list of tuples in form (feature_index, feature_value)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Progressive Validation Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 번에 하나씩 표본을 학습하면 점진적으로 훈련이 손실됩니다. 모델이 표본을 만날 때 먼저 표적을 보지 않고 예측을합니다. 그런 다음이 예측을 대상 레이블과 비교하여 오류율을 계산합니다. 오류율이 낮 으면 우리는 좋은 모델에 가깝다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Multiple passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vowpal Wabbit을 사용하면 학습률이 떨어지는 데이터 집합을 여러 번 통과시킬 수 있다.\n",
    "\n",
    "오류율이 낮아지면 데이터 세트를 여러 번 실행할 수도 있다. 트레이닝 데이터가 선형 적으로 분리 가능한 경우, 퍼셉트론은 트레이닝 세트에서 오차가 0으로 수렴된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33554432"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opts[\"D\"]\n",
    "2 ** 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 내장 된 기능으로 만 사용해서 학습 하도록 되어 있음\n",
    "\n",
    "source reference  : https://github.com/MLWave/online-learning-perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re # 정규표현식(Regular Expression)을 사용해 텍스트 데이터를 정제하기 위해\n",
    "import random # 램덤 숫자를 생성하기 위해\n",
    "from math import exp, log # 지수함수와 로그함수를 사용하기 위해\n",
    "from datetime import datetime # 시간을 계산하기 위해\n",
    "from operator import itemgetter # 키가 아닌 값으로 max, min 값을 구할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(s): \n",
    "    #   소문자 변환 문자만 허락 (특수문자 받지 않는다.)    \n",
    "    return \" \".join(re.findall(r'\\w+', s, flags = re.UNICODE)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_tsv(loc_dataset, opts):\n",
    "    #온라인 학습 방법을 통해 Data를 실행한다.\n",
    "    #tsv File을 통해 Lable, Identifier, Feature를 Parses한다.\n",
    "    #output :\n",
    "    #    label: int, The label / target (set to \"1\" if test set)\n",
    "    #    id: string, the sample identifier (movie id)\n",
    "    #    features: list of tuples, \n",
    "    #            in the form [(hashed_feature_index,feature_value)]\n",
    "    for e, line in enumerate(open(loc_dataset, \"rb\")):\n",
    "        if e > 0:\n",
    "            #    strip : 양쪽 공백을 지운다.\n",
    "            #    split : 문자열 나누기\n",
    "            r = line.decode('utf-8').strip().split(\"\\t\")\n",
    "            id = r[0]\n",
    "            \n",
    "            if opts[\"clean\"]:\n",
    "                try:\n",
    "                    r[2] = clean(r[2]) # train review\n",
    "                except:\n",
    "                    r[1] = clean(r[1]) # test review\n",
    "            # opts[\"D\"] = 2 ** 25 = 33554432\n",
    "            # Vowpal Wabbit의 Hashing trick 사용한다.\n",
    "            # Hashing trick은 큰 규모의 Feature공간을 표현\n",
    "            if len(r) == 3: \n",
    "                features = [(hash(f) % opts[\"D\"], 1) for f in r[2].split()]\n",
    "                label = int(r[1])\n",
    "            else:\n",
    "                features = [(hash(f) % opts[\"D\"], 1) for f in r[1].split()]\n",
    "                label =1\n",
    "            \n",
    "            # bigram을 사용하면 해당 Feature[i] 와 Next Feature[i+1]를 함께 해싱한다.\n",
    "            if opts[\"2grams\"]:\n",
    "                for i in range(len(features)-1):\n",
    "                    features.append((hash(str(features[i][0])+str(features[i+1][0]))%opts[\"D\"],1))\n",
    "            yield label, id, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dot_product(features, weights):\n",
    "    #    Calculate dot product from features and weights\n",
    "    #    input:\n",
    "    #        features: A list of tuples[(feature_index, feature_value)]\n",
    "    #        weights: the hashing trick weights filter\n",
    "    #        note: length is max(feature_index)\n",
    "    #    output:\n",
    "    #       dotp: the dot product\n",
    "    dotp = 0\n",
    "    for f in features:\n",
    "        dotp += weights[f[0]] * f[1]\n",
    "    return dotp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_tron(loc_dataset, opts):\n",
    "    start = datetime.now()\n",
    "    print(\"\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "    \n",
    "    if opts[\"random_init\"]:\n",
    "        random.seed(3003)\n",
    "        weights = [random.random()] * opts[\"D\"] # 0이상 1미만의 숫자 0.9038...\n",
    "    else:\n",
    "        weights = [0.] * opts[\"D\"]\n",
    "        \n",
    "    # Running training passes\n",
    "    for pass_nr in range(opts[\"n_passes\"]):\n",
    "        error_counter = 0\n",
    "        for e, (label, id, features) in enumerate(get_data_tsv(loc_dataset, opts)):\n",
    "            #   dot product 값이 Threshold value 높거나 낮은지에 따라서 \n",
    "            #   초과하면 \"1\" 미만이면 \"0\" 예측\n",
    "            dp = dot_product(features, weights) > 0.5\n",
    "            #   real Lable data에서 위 Perceptron으로 구한 dp값을 빼준다.\n",
    "            #   예측이 정확하다면, error 값은 \"0\"이며, 가중치만 남겨 둔다.\n",
    "            #   예측이 틀린 경우 error 값은 \"1\" 또는 \"-1\"이고 다음과 같이 weight를 update 한다.\n",
    "            #    weights[feature_index] += learning_rate * error * feature_value\n",
    "            error = label - dp\n",
    "            \n",
    "            #update the weight\n",
    "            if error != 0:\n",
    "                error_counter += 1\n",
    "                for index, value in features:\n",
    "                    weights[index] += opts[\"learning_rate\"] * error * log(1. + value)\n",
    "                    \n",
    "        # Reporting stuff\n",
    "        print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s\" % ( \\\n",
    "            pass_nr+1,\n",
    "            error_counter,\n",
    "            round(1 - error_counter /float(e+1),5),\n",
    "            e+1,datetime.now()-start))\n",
    "        \n",
    "        # Early stopping \n",
    "        if error_counter == 0 or error_counter < opts[\"errors_satisfied\"]:\n",
    "            print(\"%s errors found during training, halting\"%error_counter)\n",
    "            break\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_tron(loc_dataset, weights, opts):\n",
    "    #   output:\n",
    "    #   preds: list, a list with[id, prediction, dotproduct, 0-1normalized dotproduct]\n",
    "    start = datetime.now()\n",
    "    print(\"\\nTesting online\\nErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "    preds = []\n",
    "    error_counter = 0\n",
    "    for e, (label, id, features) in enumerate(get_data_tsv(loc_dataset, opts)):\n",
    "        dotp = dot_product(features, weights)\n",
    "        dp = dotp > 0.5\n",
    "        if dp > 0.5: # we predict positive class\n",
    "            preds.append([id, 1, dotp])\n",
    "        else:\n",
    "            preds.append([id, 0, dotp])\n",
    "        \n",
    "        if label -dp != 0:\n",
    "            error_counter += 1\n",
    "    print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (error_counter,round(1 - error_counter /float(e+1),5),e+1,datetime.now()-start))\n",
    "    \n",
    "    #normalizing dotproducts between 0 and 1\n",
    "    max_dotp = max(preds,key=itemgetter(2))[2]\n",
    "    min_dotp = min(preds,key=itemgetter(2))[2]\n",
    "    for p in preds:\n",
    "        p.append((p[2] - min_dotp) / float(max_dotp-min_dotp))\n",
    "    \n",
    "    # Reporting stuff\n",
    "    print(\"Done testing in %s\"%str(datetime.now()-start))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pass\t\tErrors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "1\t\t5631\t\t0.77476\t\t25000\t\t0:00:14.296742\n",
      "2\t\t3104\t\t0.87584\t\t25000\t\t0:00:26.765877\n",
      "3\t\t2235\t\t0.9106\t\t25000\t\t0:00:38.797524\n",
      "4\t\t1651\t\t0.93396\t\t25000\t\t0:00:51.068054\n",
      "5\t\t1190\t\t0.9524\t\t25000\t\t0:01:03.568560\n",
      "6\t\t980\t\t0.9608\t\t25000\t\t0:01:16.189604\n",
      "7\t\t803\t\t0.96788\t\t25000\t\t0:01:28.471190\n",
      "8\t\t553\t\t0.97788\t\t25000\t\t0:01:40.259896\n",
      "9\t\t505\t\t0.9798\t\t25000\t\t0:01:52.672252\n",
      "10\t\t507\t\t0.97972\t\t25000\t\t0:02:04.645342\n",
      "11\t\t472\t\t0.98112\t\t25000\t\t0:02:16.860410\n",
      "12\t\t333\t\t0.98668\t\t25000\t\t0:02:28.897469\n",
      "13\t\t283\t\t0.98868\t\t25000\t\t0:02:40.628088\n",
      "14\t\t210\t\t0.9916\t\t25000\t\t0:02:52.286350\n",
      "15\t\t206\t\t0.99176\t\t25000\t\t0:03:03.988705\n",
      "16\t\t157\t\t0.99372\t\t25000\t\t0:03:15.654773\n",
      "17\t\t175\t\t0.993\t\t25000\t\t0:03:27.547400\n",
      "18\t\t185\t\t0.9926\t\t25000\t\t0:03:39.820649\n",
      "19\t\t132\t\t0.99472\t\t25000\t\t0:03:52.082356\n",
      "20\t\t123\t\t0.99508\t\t25000\t\t0:04:04.514598\n",
      "21\t\t77\t\t0.99692\t\t25000\t\t0:04:16.244904\n",
      "22\t\t143\t\t0.99428\t\t25000\t\t0:04:27.966929\n",
      "23\t\t44\t\t0.99824\t\t25000\t\t0:04:39.659445\n",
      "24\t\t56\t\t0.99776\t\t25000\t\t0:04:51.353221\n",
      "25\t\t38\t\t0.99848\t\t25000\t\t0:05:03.694432\n",
      "26\t\t79\t\t0.99684\t\t25000\t\t0:05:16.356840\n",
      "27\t\t135\t\t0.9946\t\t25000\t\t0:05:28.162021\n",
      "28\t\t48\t\t0.99808\t\t25000\t\t0:05:40.419654\n",
      "29\t\t34\t\t0.99864\t\t25000\t\t0:05:52.561205\n",
      "30\t\t31\t\t0.99876\t\t25000\t\t0:06:04.879188\n",
      "31\t\t66\t\t0.99736\t\t25000\t\t0:06:17.439743\n",
      "32\t\t47\t\t0.99812\t\t25000\t\t0:06:29.548967\n",
      "33\t\t48\t\t0.99808\t\t25000\t\t0:06:42.070051\n",
      "34\t\t49\t\t0.99804\t\t25000\t\t0:06:54.787676\n",
      "35\t\t31\t\t0.99876\t\t25000\t\t0:07:07.115993\n",
      "36\t\t34\t\t0.99864\t\t25000\t\t0:07:18.874359\n",
      "37\t\t23\t\t0.99908\t\t25000\t\t0:07:30.591837\n",
      "38\t\t16\t\t0.99936\t\t25000\t\t0:07:42.307464\n",
      "39\t\t3\t\t0.99988\t\t25000\t\t0:07:54.075593\n",
      "40\t\t0\t\t1.0\t\t25000\t\t0:08:05.801262\n",
      "0 errors found during training, halting\n",
      "CPU times: user 8min 4s, sys: 1e+03 ms, total: 8min 5s\n",
      "Wall time: 8min 5s\n"
     ]
    }
   ],
   "source": [
    "#Setting options\n",
    "opts = {}\n",
    "opts[\"D\"]  = 2 ** 25\n",
    "opts[\"learning_rate\"] = 0.1\n",
    "opts[\"n_passes\"] = 80\n",
    "opts[\"errors_satisfied\"] = 0\n",
    "opts[\"random_init\"] = False\n",
    "opts[\"clean\"] = True\n",
    "opts[\"2grams\"] = True\n",
    "\n",
    "#training and saving model into weights\n",
    "%time weights = train_tron(\"/Users/JunChangWook/.kaggle/competitions/word2vec-nlp-tutorial/labeledTrainData.tsv\",opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing online\n",
      "Errors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "12295\t\t0.5082\t\t25000\t\t0:00:11.945351\n",
      "Done testing in 0:00:11.962446\n",
      "CPU times: user 11.9 s, sys: 24.6 ms, total: 12 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "# testing and saving predictions into preds\n",
    "%time preds = test_tron(\"/Users/JunChangWook/.kaggle/competitions/word2vec-nlp-tutorial/testData.tsv\",weights,opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\"12311_10\"', 1, 74.58263662824997, 0.5887163276525549],\n",
       " ['\"8348_2\"', 0, -89.7625598825129, 0.4257833974711371],\n",
       " ['\"5828_4\"', 0, -5.6144921625356, 0.509208356239691],\n",
       " ['\"7186_2\"', 0, -3.1884770305757764, 0.5116135239142375],\n",
       " ['\"12128_7\"', 1, 40.54911006275676, 0.5549752611324892],\n",
       " ['\"2913_8\"', 1, 93.78281352976059, 0.6077515118196799],\n",
       " ['\"4396_1\"', 0, -39.71733344608488, 0.47539857064320956],\n",
       " ['\"395_2\"', 0, -19.40812105567851, 0.49553326003298404],\n",
       " ['\"10616_1\"', 0, -90.7329659352967, 0.42482133040131864],\n",
       " ['\"9074_9\"', 0, -30.637105380749627, 0.48440076965365475]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing kaggle submission\n",
    "with open(\"/Users/JunChangWook/.kaggle/competitions/word2vec-nlp-tutorial/submit_perceptron.csv\",\"wb\") as outfile:\n",
    "    outfile.write('\"id\",\"sentiment\"\\n'.encode('utf-8'))\n",
    "    for p in sorted(preds):\n",
    "        outfile.write(\"{},{}\\n\".format(p[0],p[3]).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
